{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4aGpfOuhKBf",
        "outputId": "f9484f29-1d2e-4c05-8812-108bfdef210c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM6LEwMIABAj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "# Set GitHub API BASE URL\n",
        "git_url = \"https://api.github.com\"\n",
        "\n",
        "# Personal Access Token from GitHub\n",
        "git_token = \"Test Token\"\n",
        "\n",
        "# Authentication headers\n",
        "headers = {\n",
        "    \"Authorization\": f\"token {git_token}\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrape users by passing Shanghai and followers required\n",
        "def git_users():\n",
        "    users = []\n",
        "    page = 1\n",
        "    while True:\n",
        "        locationval = 'Shanghai'\n",
        "        followerslimit = 200\n",
        "        perpage = 100\n",
        "        url = f\"{git_url}/search/users?q=location:{locationval}+followers:>{followerslimit}&per_page={perpage}&page={page}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "        data = response.json()\n",
        "\n",
        "        # Break if no results\n",
        "        if 'items' not in data or len(data['items']) == 0:\n",
        "            break\n",
        "\n",
        "        # Get additional detailed information for each of the user\n",
        "        for item in data['items']:\n",
        "            user_details = get_user_details(item[\"login\"])\n",
        "            if user_details:\n",
        "                users.append(user_details)\n",
        "\n",
        "        # Exception handling\n",
        "        if response.status_code == 403:\n",
        "            print(\"Limit reached. Sleeping for 60 seconds.\")\n",
        "            time.sleep(60)\n",
        "            continue\n",
        "\n",
        "        # Next page\n",
        "        page += 1\n",
        "\n",
        "    return users"
      ],
      "metadata": {
        "id": "DO4Xj1vCAPS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrape additional detailed user information for users\n",
        "def get_user_details(username):\n",
        "    url = f\"{git_url}/users/{username}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Exception handling\n",
        "    if response.status_code == 403:\n",
        "        print(\"Limit reached. Sleeping for 60 seconds.\")\n",
        "        time.sleep(60)\n",
        "        return get_user_details(username)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Failed to fetch details for user {username}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Wapj2iJLAQhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrape up to 500 most recently pushed repositories for users\n",
        "def get_repos_for_user(username, max_repos=500):\n",
        "    repos = []\n",
        "    page = 1\n",
        "    perpage = 100\n",
        "    while len(repos) < max_repos:\n",
        "        url = f\"{git_url}/users/{username}/repos?sort=pushed&per_page={perpage}&page={page}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "        user_repos = response.json()\n",
        "\n",
        "        # Break if no results\n",
        "        if len(user_repos) == 0:\n",
        "            break\n",
        "\n",
        "        # Add to repositories and also limiting to max 500 recent repos\n",
        "        for repo in user_repos:\n",
        "            if len(repos) >= max_repos:\n",
        "                break\n",
        "            repos.append({\n",
        "                \"name\": repo[\"name\"],\n",
        "                \"login\": repo[\"owner\"][\"login\"],\n",
        "                \"full_name\": repo[\"full_name\"],\n",
        "                \"created_at\": repo[\"created_at\"],\n",
        "                \"stargazers_count\": repo[\"stargazers_count\"],\n",
        "                \"watchers_count\": repo[\"watchers_count\"],\n",
        "                \"language\": repo.get(\"language\", \"\"),\n",
        "                \"has_projects\": repo[\"has_projects\"],\n",
        "                \"has_wiki\": repo[\"has_wiki\"],\n",
        "                \"license_name\": repo[\"license\"][\"name\"] if repo[\"license\"] else None,\n",
        "                \"html_url\": repo[\"html_url\"]\n",
        "            })\n",
        "\n",
        "        # Next page\n",
        "        page += 1\n",
        "\n",
        "    return repos"
      ],
      "metadata": {
        "id": "iJ1LfyAuAUK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save users and repos data to csv\n",
        "def save_to_csv(users, repos):\n",
        "    # Path to save output\n",
        "    drive_path = '/content/drive/My Drive/TDS Proj 1/'  # Replace with your desired path\n",
        "\n",
        "    # Create users.csv\n",
        "    with open(drive_path + 'users.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "        create_file = csv.writer(file)\n",
        "        # Update header row in users.csv\n",
        "        create_file.writerow([\n",
        "            \"login\", \"name\", \"company\", \"location\", \"email\", \"hireable\", \"bio\",\n",
        "            \"public_repos\", \"followers\", \"following\", \"created_at\"\n",
        "        ])\n",
        "        # Loop each users to update all scraped information into users.csv\n",
        "        for user in users:\n",
        "            company = format_value(user.get(\"company\"))  # Get company value\n",
        "            if company:  # Check if company value is not empty\n",
        "                company = company.strip().lstrip('@').upper()  # Cleaning up company names\n",
        "\n",
        "            hireable = format_value(user.get(\"hireable\"))  # Get hierable value\n",
        "            if not hireable:  # Check if hireable value is empty\n",
        "                hireable = 'false'  # Update false for all empty cells\n",
        "\n",
        "            # Format with true and false for booleans\n",
        "            # Format with empty strings for null\n",
        "            create_file.writerow([\n",
        "                user[\"login\"], format_value(user.get(\"name\")),\n",
        "                company, format_value(user.get(\"location\")),\n",
        "                format_value(user.get(\"email\")), hireable,\n",
        "                format_value(user.get(\"bio\")), user[\"public_repos\"],\n",
        "                user[\"followers\"], user[\"following\"],\n",
        "                user[\"created_at\"]\n",
        "            ])\n",
        "     # Create repositories.csv\n",
        "    with open(drive_path + 'repositories.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "        create_file = csv.writer(file)\n",
        "        # Update header row in repositories.csv\n",
        "        create_file.writerow([\n",
        "            \"login\", \"full_name\", \"created_at\", \"stargazers_count\",\n",
        "            \"watchers_count\", \"language\", \"has_projects\", \"has_wiki\", \"license_name\"\n",
        "        ])\n",
        "        # Loop each users to update all scraped information into repositories.csv\n",
        "        for repo in repos:\n",
        "            # Format with true and false for booleans\n",
        "            # Format with empty strings for null\n",
        "            create_file.writerow([\n",
        "                repo[\"login\"], repo[\"full_name\"],\n",
        "                repo[\"created_at\"], repo[\"stargazers_count\"], repo[\"watchers_count\"],\n",
        "                format_value(repo.get(\"language\")), format_value(repo[\"has_projects\"]),\n",
        "                format_value(repo[\"has_wiki\"]), format_value(repo.get(\"license_name\"))\n",
        "            ])"
      ],
      "metadata": {
        "id": "fJ-yhTxPAXmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Get all users in Shanghai with over 200 followers\n",
        "    users = git_users()\n",
        "\n",
        "    # Get repositories for each user, limiting to 500 repos per user\n",
        "    repos = []\n",
        "    for user in users:\n",
        "        user_repos = get_repos_for_user(user[\"login\"], max_repos=500)\n",
        "        repos.extend(user_repos)\n",
        "        time.sleep(1)  # Delay to avoid rate limits\n",
        "\n",
        "    # Save data to CSV\n",
        "    save_to_csv(users, repos)\n",
        "    print(\"Data saved to users.csv and repositories.csv\")"
      ],
      "metadata": {
        "id": "BgGACvXXAYY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert booleans and replace None with empty strings\n",
        "def format_value(value):\n",
        "    if isinstance(value, bool):\n",
        "        return 'true' if value else 'false'\n",
        "    elif value is None:\n",
        "        return ''\n",
        "    else:\n",
        "        return value"
      ],
      "metadata": {
        "id": "J96Rrctfh6rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3mOmr48AcV-",
        "outputId": "5e3f6ba3-5de5-4242-a3e3-90042733f3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to users.csv and repositories.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save README\n",
        "def save_README():\n",
        "    # Path to save output\n",
        "    drive_path = '/content/drive/My Drive/TDS Proj 1/'  # Replace with your desired path\n",
        "\n",
        "    # Users CSV with required fieldswith open('README.md', 'w') as f:\n",
        "    with open(drive_path + 'README.md', 'w') as R:\n",
        "        R.write(\"\"\"\n",
        "        Scrape / Data Collection Process:\n",
        "\n",
        "        -  To scrape/collect the required  data from GitHub, I leveraged the GitHub REST API to gather details about users in Shanghai with over 200 followers and their most recently pushed repositories with maximum limit to 500 repositories\n",
        "\n",
        "        -  I used my personal access token for authentication to access GITHUB API to avoid rate-limiting issues. The code includes error handling to pause execution in case rate limits are exceeded\n",
        "\n",
        "        -  To retrieve all relevant users, pagination was implemented to handle the API's limitation of returning a maximum of 100 users per request. The code iterates through pages of results until all matching users are obtained\n",
        "\n",
        "        -  For each identified user, a separate API call was made to retrieve detailed user information\n",
        "\n",
        "        -  The 'company' field was cleaned by removing leading/trailing spaces and any '@' symbol at the beginning.\n",
        "\n",
        "        -  Company names were then converted to uppercase\n",
        "\n",
        "        -  Additionally, all boolean fields were standardized to contain either 'true' or 'false' values\n",
        "\n",
        "        -  All extracted user and repository data were stored in separate CSV files named 'users.csv' and 'repositories.csv', respectively\n",
        "\n",
        "\n",
        "\n",
        "        Some of the Interesting and surprising facts that I see in the data post analyzing are:\n",
        "\n",
        "        -  While Shanghai's GitHub users are employed across various companies.  Among them users with over 200 followers who have provided company information, roughly 5% are affiliated with ByteDance, a leading Chinese internet technology company\n",
        "\n",
        "        -  While 29% of the 742 total users are open to hiring opportunities, the majority (71%) appear to be primarily using the platform for skill development and learning\n",
        "\n",
        "        -  Peng-zhihui leads in followers with 80,714 and 59 repositories, followed closely by ruanyf with 79,328 followers and 72 repositories\n",
        "\n",
        "        -  In contrast to Peng-zhihui and ruanyf, who have a large following, Hengle possesses the most repositories, with a remarkable count of 11,057\n",
        "\n",
        "        -  It is surprising to find that the stargazer and watcher counts are uniform across all users\n",
        "\n",
        "        -  Between 2008 and 2013, the number of repositories created by Shanghai users skyrocketed by over 95 times, from a mere 20 to a staggering 1900+. This reflects the rapid adoption of GitHub and a surge in open-source contributions from the Shanghai developer community\n",
        "\n",
        "        -  The year 2018 marked the peak of repository creation for Shanghai users, with more new repositories added. This suggests a high level of development activity and innovation within the community during that period.  In the past few years (2019-2024), there has been a noticeable decline in the number of new repositories created, dropping by nearly 39% from the 2018 peak. This trend might indicate a shift in development practices or a saturation point in repository creation\n",
        "\n",
        "\n",
        "\n",
        "        Recommendation for developers basis my analysis:\n",
        "\n",
        "        -  Shanghai's developers initially favored JavaScript, Python, and Java, accounting for almost 44% of repositories where language data information exists. However, a clear shift is evident in the last two years, with Python and TypeScript gaining traction as the preferred languages for new projects, even amidst a diverse landscape of 87 different programming languages utilized by developers. Developers should consider learning and utilizing these languages in their projects. This can increase the visibility and relevance of their work within the developer community\n",
        "\n",
        "        -  Some of the most popular open sources licenses used by developers are MIT License and Apache License 2.0.  MIT and Apache licenses are permissive licenses and widely used in open-source projects. Key differences lie in their handling of patents and trademarks, where Apache has an advantage with more explicti protection\n",
        "\n",
        "        -  The vast majority of repositories (98%) have projects enabled, and a significant portion of those projects (86%) also include a wiki.  Developers should utilize these features to organize and document their work effectively to improve project clarity and make it easier for other to contribute\n",
        "\n",
        "        -  Repository names and descriptions play a cruicial role in discoverability and attach collaborators, so need to make it clear, concise, and relevant to the project's content\n",
        "\n",
        "        -  Only 29% of the Developers updated hiring preference.  Developers who are open to hiring should actively update their profiles and highlight their skills and experience to attract potential employers\n",
        "\n",
        "        -  Stay informed about emerging technologies, trends, and best practices within the developer community. Follow influential developers and organizations, participate in relevant discussions, and attend workshops or conferences\n",
        "\n",
        "        \"\"\")\n",
        "    print(\"Data saved to README.md\")"
      ],
      "metadata": {
        "id": "1SuomlR2Tv2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_README()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7gZ87VA_uCq",
        "outputId": "cb6f9767-30bd-42d4-e9db-b41eed74064d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to README.md\n"
          ]
        }
      ]
    }
  ]
}